# Emotion Recognition using Audio-Visual Data

## Overview
This project focuses on **emotion recognition** using both **audio** and **visual** data. The main tasks are:
1. **Data Visualization using t-SNE and PCA**: Reduce dimensionality of facial landmark data for emotion classification visualization.
2. **Emotion Classification using Facial Landmarks**: Classify emotions based on facial landmarks extracted from video frames.
3. **Emotion Classification using Audio Features**: Classify emotions based on audio features extracted from speech signals.
4. **CNN for Emotion Classification based on Facial Images**: Train a CNN to classify emotions from facial images.
5. **3D-CNN for Emotion Classification from Video Sequences**: Classify emotions using video sequences with a 3D CNN.
6. **CNN for Spectrogram Emotion Classification**: Classify emotions based on speech spectrograms.

The project is structured into different tasks, with each task focusing on a specific aspect of the emotion recognition pipeline. 

## Requirements

To run the project, you'll need Python 3.8 and the required dependencies. You can install them using the provided `requirements.txt`.

### Setup
1. Clone the repository:
   ```bash
   git clone https://github.com/richardtekere09/Emotion-Recognition-using-Audio-Visual-Data
   cd emotion-recognition-project
